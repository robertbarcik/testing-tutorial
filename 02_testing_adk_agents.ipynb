{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ADK Agents: From Simple LLMs to Agentic Behavior\n",
    "\n",
    "**Course:** LLM and Agent Testing - Lesson 2  \n",
    "**Domain:** IT Support/Services Company  \n",
    "**Environment:** Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Build testable agents using Google's ADK (Agent Development Kit)\n",
    "2. Test agent tool selection (which tools the agent chooses to call)\n",
    "3. Test tool parameters (accuracy of extracted information)\n",
    "4. Test multi-step reasoning (tool call sequences)\n",
    "5. Test edge cases (invalid inputs, ambiguous requests)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Context: Why Agent Testing is Different\n",
    "\n",
    "### Quick Recap: Notebook 01\n",
    "\n",
    "In the previous lesson, you learned to:\n",
    "- ✅ Write automated tests with pytest\n",
    "- ✅ Test LLM text outputs for factual correctness\n",
    "- ✅ Validate structured outputs with Pydantic\n",
    "- ✅ Use parameterized tests\n",
    "\n",
    "### What's Different with Agents?\n",
    "\n",
    "**Simple LLM (Notebook 01):**\n",
    "```\n",
    "User: \"What port does SSH use?\"\n",
    "LLM: \"Port 22\"\n",
    "Test: Check if response contains \"22\" ✅\n",
    "```\n",
    "\n",
    "**Agent with Tools (This Notebook):**\n",
    "```\n",
    "User: \"What's the status of ticket #5678?\"\n",
    "Agent: Thinks... I need to look up this ticket\n",
    "       Calls: lookup_ticket(\"5678\")\n",
    "       Tool returns: {ticket_id: 5678, status: \"In Progress\", ...}\n",
    "       Agent: \"Ticket #5678 is currently In Progress...\"\n",
    "       \n",
    "Test: Did agent call the right tool? ✅\n",
    "Test: Did agent extract correct ticket ID? ✅\n",
    "Test: Did agent use the tool results properly? ✅\n",
    "```\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Simple LLM Testing | Agent Testing |\n",
    "|-------------------|---------------|\n",
    "| Test final text output | Test tool selection & parameters |\n",
    "| Single-step response | Multi-step reasoning |\n",
    "| Stateless | Stateful (tool results affect next steps) |\n",
    "| Straightforward assertions | Test tool call sequences |\n",
    "\n",
    "### What We're Building Today\n",
    "\n",
    "An **IT Support Agent** with these tools:\n",
    "- 🎫 `lookup_ticket(ticket_id)` - Retrieve ticket details\n",
    "- 📚 `search_knowledge_base(query)` - Find help articles\n",
    "- 🔍 `check_system_status(service)` - Check if systems are up\n",
    "\n",
    "**Testing scenarios:**\n",
    "- User asks about a ticket → Agent calls `lookup_ticket` with correct ID\n",
    "- User has a problem → Agent searches KB for solution\n",
    "- User asks multi-step question → Agent calls multiple tools in order\n",
    "\n",
    "---\n",
    "\n",
    "Let's get started! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, we'll install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-adk litellm openai python-dotenv nest-asyncio deprecated google-genai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Optional, Dict, Any\n",
    "import nest_asyncio\n",
    "\n",
    "# Enable nested event loops (required for Colab)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Core ADK imports\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.genai import types\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Key Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"✅ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    from getpass import getpass\n",
    "    print(\"💡 To use Colab secrets: Go to 🔑 (left sidebar) → Add new secret → Name: OPENAI_API_KEY\")\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n",
    "    raise ValueError(\"❌ ERROR: No API key provided!\")\n",
    "\n",
    "print(\"✅ Authentication configured!\")\n",
    "\n",
    "# Model configuration\n",
    "OPENAI_MODEL = \"gpt-5-nano\"\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Testable IT Support Agent\n",
    "\n",
    "Let's build a simple IT support agent with three tools. These tools will return mock data for fast testing.\n",
    "\n",
    "### Understanding ADK Tool Structure\n",
    "\n",
    "An ADK tool consists of:\n",
    "1. **Function** - The actual code that runs\n",
    "2. **Tool definition** - Describes the function to the agent\n",
    "3. **Registration** - Adding the tool to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Lookup Ticket\n",
    "def lookup_ticket(ticket_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Look up details for a support ticket.\n",
    "    \n",
    "    Args:\n",
    "        ticket_id: The ticket ID to look up (e.g., \"5678\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with ticket details\n",
    "    \"\"\"\n",
    "    mock_tickets = {\n",
    "        \"5678\": {\n",
    "            \"ticket_id\": \"5678\",\n",
    "            \"status\": \"In Progress\",\n",
    "            \"priority\": \"High\",\n",
    "            \"user\": \"Alice Johnson\",\n",
    "            \"issue\": \"Cannot access email\",\n",
    "            \"assigned_to\": \"Tech Support Team\"\n",
    "        },\n",
    "        \"1234\": {\n",
    "            \"ticket_id\": \"1234\",\n",
    "            \"status\": \"Resolved\",\n",
    "            \"priority\": \"Medium\",\n",
    "            \"user\": \"Bob Smith\",\n",
    "            \"issue\": \"Printer not working\",\n",
    "            \"assigned_to\": \"Hardware Team\"\n",
    "        },\n",
    "        \"9999\": {\n",
    "            \"ticket_id\": \"9999\",\n",
    "            \"status\": \"Open\",\n",
    "            \"priority\": \"Critical\",\n",
    "            \"user\": \"Charlie Brown\",\n",
    "            \"issue\": \"Server down\",\n",
    "            \"assigned_to\": \"Infrastructure Team\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if ticket_id in mock_tickets:\n",
    "        return mock_tickets[ticket_id]\n",
    "    else:\n",
    "        return {\"error\": f\"Ticket {ticket_id} not found\"}\n",
    "\n",
    "\n",
    "# Tool 2: Search Knowledge Base\n",
    "def search_knowledge_base(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Search the IT knowledge base for help articles.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query (e.g., \"how to reset password\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with search results\n",
    "    \"\"\"\n",
    "    mock_kb = {\n",
    "        \"password\": [\n",
    "            {\"title\": \"How to Reset Your Password\", \"article_id\": \"KB001\"},\n",
    "            {\"title\": \"Password Requirements\", \"article_id\": \"KB002\"}\n",
    "        ],\n",
    "        \"email\": [\n",
    "            {\"title\": \"Troubleshooting Email Access\", \"article_id\": \"KB010\"},\n",
    "            {\"title\": \"Email Configuration Guide\", \"article_id\": \"KB011\"}\n",
    "        ],\n",
    "        \"vpn\": [\n",
    "            {\"title\": \"VPN Setup Instructions\", \"article_id\": \"KB020\"},\n",
    "            {\"title\": \"VPN Connection Issues\", \"article_id\": \"KB021\"}\n",
    "        ],\n",
    "        \"printer\": [\n",
    "            {\"title\": \"Printer Offline Solutions\", \"article_id\": \"KB030\"},\n",
    "            {\"title\": \"How to Install Printer Drivers\", \"article_id\": \"KB031\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    query_lower = query.lower()\n",
    "    results = []\n",
    "    \n",
    "    for keyword, articles in mock_kb.items():\n",
    "        if keyword in query_lower:\n",
    "            results.extend(articles)\n",
    "    \n",
    "    if results:\n",
    "        return {\"query\": query, \"results\": results, \"count\": len(results)}\n",
    "    else:\n",
    "        return {\"query\": query, \"results\": [], \"count\": 0}\n",
    "\n",
    "\n",
    "# Tool 3: Check System Status\n",
    "def check_system_status(service_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Check the operational status of a service or system.\n",
    "    \n",
    "    Args:\n",
    "        service_name: Name of the service (e.g., \"email\", \"vpn\", \"database\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with service status\n",
    "    \"\"\"\n",
    "    mock_status = {\n",
    "        \"email\": {\"service\": \"email\", \"status\": \"operational\", \"uptime\": \"99.9%\"},\n",
    "        \"vpn\": {\"service\": \"vpn\", \"status\": \"operational\", \"uptime\": \"100%\"},\n",
    "        \"database\": {\"service\": \"database\", \"status\": \"degraded\", \"uptime\": \"95.2%\"},\n",
    "        \"file_server\": {\"service\": \"file_server\", \"status\": \"down\", \"uptime\": \"0%\"},\n",
    "        \"web_portal\": {\"service\": \"web_portal\", \"status\": \"operational\", \"uptime\": \"99.5%\"}\n",
    "    }\n",
    "    \n",
    "    service_lower = service_name.lower().replace(\" \", \"_\")\n",
    "    \n",
    "    if service_lower in mock_status:\n",
    "        return mock_status[service_lower]\n",
    "    else:\n",
    "        return {\"service\": service_name, \"status\": \"unknown\"}\n",
    "\n",
    "\n",
    "print(\"✅ Tools defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the ADK Agent\n",
    "\n",
    "Now we'll create an ADK agent and register our tools.\n",
    "\n",
    "**Note:** In ADK, you can pass Python functions directly as tools. The agent will automatically understand them based on their docstrings and type hints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LiteLlm model instance for OpenAI\n",
    "llm_model = LiteLlm(\n",
    "    model=f\"openai/{OPENAI_MODEL}\",\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# Create the IT Support Agent\n",
    "it_support_agent = LlmAgent(\n",
    "    name=\"it_support_agent\",\n",
    "    model=llm_model,\n",
    "    description=\"An IT support agent that helps users with tickets, knowledge base searches, and system status checks\",\n",
    "    instruction=\"\"\"You are an IT support agent. Help users with their IT issues by:\n",
    "    1. Looking up ticket information when asked about specific tickets\n",
    "    2. Searching the knowledge base for solutions to problems\n",
    "    3. Checking system status when users report service issues\n",
    "    \n",
    "    Always use the appropriate tools to get accurate information.\"\"\",\n",
    "    tools=[lookup_ticket, search_knowledge_base, check_system_status]\n",
    ")\n",
    "\n",
    "print(\"✅ IT Support Agent created!\")\n",
    "print(f\"Agent has {len(it_support_agent.tools)} tools available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Function for Testing\n",
    "\n",
    "We need a simple way to run the agent and capture tool calls for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent_and_get_tools(user_message: str, session_id: str = \"test_session\"):\n",
    "    \"\"\"\n",
    "    Run the agent and capture tool calls.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'tool_calls': list of {name, parameters},\n",
    "            'tool_count': int,\n",
    "            'response': str\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Create session\n",
    "    session_service = InMemorySessionService()\n",
    "    user_id = \"test_user\"\n",
    "    \n",
    "    await session_service.create_session(\n",
    "        app_name=\"it_support_test\",\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        state={}\n",
    "    )\n",
    "    \n",
    "    # Create runner\n",
    "    runner = Runner(\n",
    "        app_name=\"it_support_test\",\n",
    "        agent=it_support_agent,\n",
    "        session_service=session_service\n",
    "    )\n",
    "    \n",
    "    # Format message and run\n",
    "    content = types.Content(role='user', parts=[types.Part(text=user_message)])\n",
    "    events = runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    # Collect tool calls and response\n",
    "    tool_calls = []\n",
    "    final_response = \"\"\n",
    "    \n",
    "    async for event in events:\n",
    "        if hasattr(event, 'tool_use') and event.tool_use:\n",
    "            for tool_use in event.tool_use:\n",
    "                tool_calls.append({\n",
    "                    'name': tool_use.name if hasattr(tool_use, 'name') else str(tool_use),\n",
    "                    'parameters': tool_use.input if hasattr(tool_use, 'input') else {}\n",
    "                })\n",
    "        \n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    return {\n",
    "        'tool_calls': tool_calls,\n",
    "        'tool_count': len(tool_calls),\n",
    "        'response': final_response\n",
    "    }\n",
    "\n",
    "print(\"✅ Helper function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Tool Selection\n",
    "\n",
    "The first thing to test: **Does the agent choose the right tool?**\n",
    "\n",
    "This is fundamental - if the agent picks the wrong tool, nothing else matters!\n",
    "\n",
    "### Pattern: Test Tool Selection\n",
    "\n",
    "```python\n",
    "1. Give agent a task that requires a specific tool\n",
    "2. Run the agent\n",
    "3. Assert that the expected tool was called\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Agent calls lookup_ticket tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: When user asks about a ticket, agent should call lookup_ticket\n",
    "user_message = \"Can you check the status of ticket 5678?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_1\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {result['tool_count']}\")\n",
    "print(f\"Tool names: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "print(f\"\\nAgent response: {result['response'][:200]}...\\n\")\n",
    "\n",
    "# Assertions\n",
    "assert result['tool_count'] > 0, \"❌ Agent should have called at least one tool\"\n",
    "tool_names = [tc['name'] for tc in result['tool_calls']]\n",
    "assert 'lookup_ticket' in tool_names, f\"❌ Expected 'lookup_ticket', got: {tool_names}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly called lookup_ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Agent calls knowledge base search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: When user has a problem, agent should search knowledge base\n",
    "user_message = \"How do I reset my password?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_2\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {result['tool_count']}\")\n",
    "print(f\"Tool names: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "print(f\"\\nAgent response: {result['response'][:200]}...\\n\")\n",
    "\n",
    "# Assertions\n",
    "tool_names = [tc['name'] for tc in result['tool_calls']]\n",
    "assert 'search_knowledge_base' in tool_names, f\"❌ Expected 'search_knowledge_base', got: {tool_names}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly called search_knowledge_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Agent calls system status check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: When user asks about system status, agent should check status\n",
    "user_message = \"Is the email service working?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_3\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {result['tool_count']}\")\n",
    "print(f\"Tool names: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "print(f\"\\nAgent response: {result['response'][:200]}...\\n\")\n",
    "\n",
    "# Assertions\n",
    "tool_names = [tc['name'] for tc in result['tool_calls']]\n",
    "assert 'check_system_status' in tool_names, f\"❌ Expected 'check_system_status', got: {tool_names}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly called check_system_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight: Testing Behavior, Not Text\n",
    "\n",
    "Notice what we're testing:\n",
    "- ✅ **We test**: Which tool was called\n",
    "- ❌ **We don't test**: The exact text of the response\n",
    "\n",
    "Why? Because:\n",
    "1. Tool calls are **deterministic** (agent logic)\n",
    "2. Text responses are **variable** (natural language)\n",
    "3. Tool calls prove the agent **understood** the task\n",
    "4. Tool calls are what **actually matter** for functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing Tool Parameters\n",
    "\n",
    "Choosing the right tool is good. But did the agent extract the correct parameters?\n",
    "\n",
    "**Example:**\n",
    "- User: \"Check ticket 5678\"\n",
    "- Agent calls: `lookup_ticket(\"5678\")` ✅\n",
    "- Agent calls: `lookup_ticket(\"1234\")` ❌ Wrong ticket!\n",
    "\n",
    "### Pattern: Test Parameter Extraction\n",
    "\n",
    "```python\n",
    "1. Give agent a task with specific information\n",
    "2. Run the agent\n",
    "3. Assert the tool was called with correct parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Agent extracts ticket ID correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent correctly extracts ticket ID from user message\n",
    "user_message = \"What's the status of ticket 5678?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_4\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "\n",
    "# Find the lookup_ticket call\n",
    "ticket_calls = [tc for tc in result['tool_calls'] if tc['name'] == 'lookup_ticket']\n",
    "assert len(ticket_calls) > 0, \"❌ Agent should have called lookup_ticket\"\n",
    "\n",
    "# Check the ticket_id parameter\n",
    "ticket_id = ticket_calls[0]['parameters'].get('ticket_id')\n",
    "print(f\"Extracted ticket_id: {ticket_id}\\n\")\n",
    "\n",
    "assert ticket_id == \"5678\", f\"❌ Expected ticket_id '5678', but got: {ticket_id}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly extracted ticket ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: Agent extracts search query correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent correctly extracts and formats search query\n",
    "user_message = \"I need help with VPN connection issues\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_5\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "\n",
    "# Find the KB search call\n",
    "kb_calls = [tc for tc in result['tool_calls'] if tc['name'] == 'search_knowledge_base']\n",
    "assert len(kb_calls) > 0, \"❌ Agent should have called search_knowledge_base\"\n",
    "\n",
    "# Check that query contains relevant keywords\n",
    "query = kb_calls[0]['parameters'].get('query', '').lower()\n",
    "print(f\"Search query: {query}\\n\")\n",
    "\n",
    "assert 'vpn' in query, f\"❌ Query should contain 'vpn', but got: {query}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly extracted search query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 6: Agent extracts service name correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent correctly identifies service name from user query\n",
    "user_message = \"Is the email service operational right now?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_6\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "\n",
    "# Find the status check call\n",
    "status_calls = [tc for tc in result['tool_calls'] if tc['name'] == 'check_system_status']\n",
    "assert len(status_calls) > 0, \"❌ Agent should have called check_system_status\"\n",
    "\n",
    "# Check the service name\n",
    "service = status_calls[0]['parameters'].get('service_name', '').lower()\n",
    "print(f\"Service name: {service}\\n\")\n",
    "\n",
    "assert 'email' in service, f\"❌ Service name should contain 'email', but got: {service}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly extracted service name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Parameter Testing Matters\n",
    "\n",
    "Imagine these scenarios:\n",
    "\n",
    "**Scenario 1: Correct Parameters** ✅\n",
    "```\n",
    "User: \"Check ticket 5678\"\n",
    "Agent: lookup_ticket(\"5678\") → Returns correct ticket\n",
    "User: Happy! Gets the right information\n",
    "```\n",
    "\n",
    "**Scenario 2: Wrong Parameters** ❌\n",
    "```\n",
    "User: \"Check ticket 5678\"\n",
    "Agent: lookup_ticket(\"1234\") → Returns wrong ticket\n",
    "User: Confused! Gets incorrect information\n",
    "```\n",
    "\n",
    "**Testing parameters ensures data integrity!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing Multi-Step Reasoning\n",
    "\n",
    "Real-world agent tasks often require multiple steps:\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "User: \"Check ticket 5678 and find solutions for the issue\"\n",
    "\n",
    "Step 1: Agent calls lookup_ticket(\"5678\")\n",
    "        Returns: {issue: \"Cannot access email\"}\n",
    "        \n",
    "Step 2: Agent calls search_knowledge_base(\"email access\")\n",
    "        Returns: [KB articles about email]\n",
    "        \n",
    "Step 3: Agent synthesizes information and responds\n",
    "```\n",
    "\n",
    "### Pattern: Test Tool Call Sequences\n",
    "\n",
    "```python\n",
    "1. Give agent a multi-step task\n",
    "2. Run the agent\n",
    "3. Assert on tool count\n",
    "4. Assert on tool call order\n",
    "5. Assert on parameter correctness across calls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 7: Multi-step reasoning (ticket then KB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent performs multi-step reasoning\n",
    "# 1. Looks up ticket to understand the issue\n",
    "# 2. Searches KB for solutions\n",
    "user_message = \"Check ticket 5678 and help me find solutions for the issue\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_7\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {result['tool_count']}\")\n",
    "tool_sequence = [tc['name'] for tc in result['tool_calls']]\n",
    "print(f\"Tool sequence: {tool_sequence}\\n\")\n",
    "\n",
    "# Assert multiple tools were called\n",
    "assert result['tool_count'] >= 2, f\"❌ Expected at least 2 tool calls, but got: {result['tool_count']}\"\n",
    "\n",
    "# Assert that both tools were called\n",
    "assert 'lookup_ticket' in tool_sequence, \"❌ Agent should look up the ticket\"\n",
    "assert 'search_knowledge_base' in tool_sequence, \"❌ Agent should search KB for solutions\"\n",
    "\n",
    "# Assert correct order: ticket lookup should come before KB search\n",
    "ticket_index = tool_sequence.index('lookup_ticket')\n",
    "kb_index = tool_sequence.index('search_knowledge_base')\n",
    "assert ticket_index < kb_index, f\"❌ Agent should look up ticket before searching KB, but order was: {tool_sequence}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly performed multi-step reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 8: Single tool when appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent uses single tool when that's all that's needed\n",
    "# Not every query requires multiple steps!\n",
    "user_message = \"What's the status of ticket 1234?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_8\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {result['tool_count']}\")\n",
    "print(f\"Tool names: {[tc['name'] for tc in result['tool_calls']]}\\n\")\n",
    "\n",
    "# For this simple query, should only need lookup_ticket\n",
    "assert result['tool_count'] == 1, f\"❌ Simple ticket lookup should use 1 tool, but used: {result['tool_count']}\"\n",
    "assert result['tool_calls'][0]['name'] == 'lookup_ticket', \"❌ Should use lookup_ticket\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent correctly used single tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tool Call Order\n",
    "\n",
    "Why does order matter?\n",
    "\n",
    "**Good Order:**\n",
    "```\n",
    "1. lookup_ticket(\"5678\") → Get issue: \"email access\"\n",
    "2. search_knowledge_base(\"email access\") → Find relevant articles\n",
    "3. Provide informed response\n",
    "```\n",
    "\n",
    "**Bad Order:**\n",
    "```\n",
    "1. search_knowledge_base(\"unknown\") → Generic results\n",
    "2. lookup_ticket(\"5678\") → Too late, already gave bad advice\n",
    "```\n",
    "\n",
    "**Testing ensures logical reasoning flow!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Edge Cases\n",
    "\n",
    "What happens when things go wrong or are unclear?\n",
    "\n",
    "**Edge cases to test:**\n",
    "1. ❓ **Ambiguous requests** - \"Help me with my problem\" (what problem?)\n",
    "2. ❌ **Invalid data** - \"Check ticket XYZ\" (invalid ticket ID)\n",
    "3. 🤷 **No tool needed** - \"What is IT support?\" (general question)\n",
    "4. 🔀 **Multiple interpretations** - \"Check the email\" (ticket or system status?)\n",
    "\n",
    "### Why Test Edge Cases?\n",
    "\n",
    "In production:\n",
    "- Users won't always provide perfect input\n",
    "- Systems may return errors\n",
    "- Requests may be vague or ambiguous\n",
    "\n",
    "**Your agent needs to handle these gracefully!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 9: General question (no tool needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent handles general questions without calling tools\n",
    "user_message = \"What is IT support?\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_9\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {result['tool_count']}\")\n",
    "print(f\"\\nAgent response: {result['response'][:200]}...\\n\")\n",
    "\n",
    "# For a general question, agent shouldn't need tools\n",
    "assert result['tool_count'] == 0, f\"❌ General question shouldn't require tools, but {result['tool_count']} tools were called\"\n",
    "\n",
    "# Should still provide a response\n",
    "assert len(result['response']) > 0, \"❌ Agent should provide a response\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent handled general question without tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 10: Invalid ticket ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent attempts to look up non-existent ticket\n",
    "# The tool will return an error, agent should handle it\n",
    "user_message = \"Check ticket 99999999\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_10\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "print(f\"\\nAgent response: {result['response'][:200]}...\\n\")\n",
    "\n",
    "# Agent should still try to look up the ticket\n",
    "tool_names = [tc['name'] for tc in result['tool_calls']]\n",
    "assert 'lookup_ticket' in tool_names, \"❌ Agent should attempt ticket lookup\"\n",
    "\n",
    "# The final response should indicate the ticket wasn't found\n",
    "response_lower = result['response'].lower()\n",
    "assert ('not found' in response_lower or 'doesn\\'t exist' in response_lower or \n",
    "        'invalid' in response_lower or 'error' in response_lower), \\\n",
    "       f\"❌ Response should indicate ticket not found\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent handled invalid ticket ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 11: Noisy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Agent extracts ticket ID from messy/noisy user input\n",
    "user_message = \"Hey, so like, I was wondering, could you maybe check ticket 5678 for me? Thanks!\"\n",
    "result = await run_agent_and_get_tools(user_message, session_id=\"test_11\")\n",
    "\n",
    "print(f\"User: {user_message}\")\n",
    "print(f\"\\nTools called: {[tc['name'] for tc in result['tool_calls']]}\")\n",
    "\n",
    "# Agent should extract the ticket ID despite the noise\n",
    "ticket_calls = [tc for tc in result['tool_calls'] if tc['name'] == 'lookup_ticket']\n",
    "assert len(ticket_calls) > 0, \"❌ Agent should extract ticket ID from noisy input\"\n",
    "\n",
    "ticket_id = ticket_calls[0]['parameters'].get('ticket_id')\n",
    "print(f\"Extracted ticket_id: {ticket_id}\\n\")\n",
    "\n",
    "assert ticket_id == \"5678\", f\"❌ Expected ticket '5678', but got: {ticket_id}\"\n",
    "\n",
    "print(\"✅ TEST PASSED: Agent extracted info from noisy input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Case Testing Strategy\n",
    "\n",
    "When testing edge cases, consider:\n",
    "\n",
    "1. **Invalid inputs** - What if data is malformed?\n",
    "2. **Missing information** - What if user doesn't provide required details?\n",
    "3. **Ambiguity** - What if request could mean multiple things?\n",
    "4. **Error conditions** - What if tools fail or return errors?\n",
    "5. **Boundary conditions** - What about extreme values or edge values?\n",
    "\n",
    "**Good agents degrade gracefully, not catastrophically!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Student Exercises 🎓\n",
    "\n",
    "Now it's your turn! Apply what you've learned about testing agents.\n",
    "\n",
    "### Exercise 1: Test Different Ticket IDs\n",
    "\n",
    "Write tests for ticket IDs: 1234, 9999. Verify the agent:\n",
    "1. Calls lookup_ticket\n",
    "2. Extracts the correct ticket ID\n",
    "3. Provides appropriate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "# Test ticket 1234\n",
    "\n",
    "# Test ticket 9999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Test Tool Disambiguation\n",
    "\n",
    "Write a test where the user says \"Check the database\". The agent could:\n",
    "- Call `lookup_ticket` if they think it's a ticket\n",
    "- Call `check_system_status` if they think it's the service\n",
    "\n",
    "Which one should the agent choose? Test your hypothesis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Add a New Tool and Test It\n",
    "\n",
    "Create a new tool `restart_service(service_name: str)` that simulates restarting an IT service.\n",
    "\n",
    "**Requirements:**\n",
    "1. Write the tool function\n",
    "2. Add it to the agent (you'll need to recreate the agent)\n",
    "3. Write 2 tests:\n",
    "   - Test that agent calls restart_service when asked to restart\n",
    "   - Test that agent extracts correct service name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "\n",
    "def restart_service(service_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    TODO: Implement this function\n",
    "    Should return a dict with restart status\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# TODO: Recreate agent with the new tool\n",
    "# TODO: Write tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Test Multiple Tickets\n",
    "\n",
    "Write a test where the user says \"Compare tickets 5678 and 1234\".\n",
    "\n",
    "**Assert:**\n",
    "1. Agent looks up both tickets\n",
    "2. Both ticket IDs are correctly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Create a Failing Test\n",
    "\n",
    "Write a test that you EXPECT to fail. Then explain:\n",
    "1. Why it fails\n",
    "2. Is it a bug in the agent or a test problem?\n",
    "3. How would you fix it?\n",
    "\n",
    "**Example failing scenarios:**\n",
    "- Agent calls wrong tool\n",
    "- Agent extracts wrong parameter\n",
    "- Agent doesn't handle edge case\n",
    "- Test is too strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Your failing test here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your explanation here:**\n",
    "\n",
    "<!-- \n",
    "TODO: Explain:\n",
    "- What test did you write?\n",
    "- Why does it fail?\n",
    "- Is it agent bug or test bug?\n",
    "- How to fix?\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices for Agent Testing\n",
    "\n",
    "### ✅ DO:\n",
    "\n",
    "1. **Test behavior, not text** - Focus on tool calls and parameters\n",
    "2. **Test tool selection first** - Ensure agent picks the right tool\n",
    "3. **Test parameter accuracy** - Verify extracted information is correct\n",
    "4. **Test tool call sequences** - Multi-step reasoning matters\n",
    "5. **Test edge cases** - Invalid input, missing data, ambiguity\n",
    "6. **Use mock data** - Fast tests with fake/mock tool responses\n",
    "7. **Test happy path AND failures** - Both success and error cases\n",
    "8. **Write descriptive test names** - Make it clear what you're testing\n",
    "\n",
    "### ❌ DON'T:\n",
    "\n",
    "1. **Don't test only final text** - Tool calls are more important\n",
    "2. **Don't expect exact tool sequences** - Some variation is OK\n",
    "3. **Don't skip edge cases** - That's where bugs hide\n",
    "4. **Don't use real external services** - Slow and unreliable\n",
    "5. **Don't test too many things in one test** - Keep tests focused\n",
    "\n",
    "### Testing Hierarchy\n",
    "\n",
    "**Priority 1: Critical Functionality**\n",
    "- Does agent call the right tool?\n",
    "- Does agent extract correct parameters?\n",
    "\n",
    "**Priority 2: Complex Behavior**\n",
    "- Multi-step reasoning\n",
    "- Tool call ordering\n",
    "\n",
    "**Priority 3: Edge Cases**\n",
    "- Invalid inputs\n",
    "- Error handling\n",
    "- Ambiguous requests\n",
    "\n",
    "**Priority 4: Output Quality**\n",
    "- Response helpfulness\n",
    "- Text clarity\n",
    "- (This is for next lesson: LLM-as-judge!)\n",
    "\n",
    "### Agent Testing vs LLM Testing\n",
    "\n",
    "| Aspect | LLM Testing (Notebook 01) | Agent Testing (This Notebook) |\n",
    "|--------|---------------------------|-------------------------------|\n",
    "| **What to test** | Text outputs | Tool calls & parameters |\n",
    "| **Assertions** | String contains, JSON structure | Tool names, parameter values |\n",
    "| **Complexity** | Single response | Multi-step sequences |\n",
    "| **Determinism** | Medium (LLM variability) | High (tool logic) |\n",
    "| **Focus** | Content correctness | Behavior correctness |\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "**Pitfall 1: Over-testing text**\n",
    "```python\n",
    "❌ assert \"The ticket status is In Progress\" == response\n",
    "✅ assert 'lookup_ticket' in tool_calls\n",
    "```\n",
    "\n",
    "**Pitfall 2: Brittle sequence assertions**\n",
    "```python\n",
    "❌ assert tool_sequence == ['tool1', 'tool2', 'tool3']  # Too strict\n",
    "✅ assert 'tool1' in tool_sequence and 'tool2' in tool_sequence  # Flexible\n",
    "```\n",
    "\n",
    "**Pitfall 3: Not testing edge cases**\n",
    "```python\n",
    "❌ Only test: \"Check ticket 5678\"\n",
    "✅ Also test: \"Check ticket XYZ\", \"Check ticket\", \"Check tickets 1, 2, 3\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways & Next Steps\n",
    "\n",
    "### 🎉 What You've Learned\n",
    "\n",
    "1. **Agents are different** - Test behavior (tool calls) not just text\n",
    "2. **Tool selection matters** - Right tool = right functionality\n",
    "3. **Parameters must be accurate** - Wrong parameters = wrong results\n",
    "4. **Multi-step reasoning is testable** - Assert on sequences and order\n",
    "5. **Edge cases reveal bugs** - Test invalid, ambiguous, and error cases\n",
    "6. **ADK makes testing easier** - Structured tool calls are inspectable\n",
    "\n",
    "### 🚀 What You Can Do Now\n",
    "\n",
    "- ✅ Build testable agents with ADK\n",
    "- ✅ Test tool selection and parameters\n",
    "- ✅ Test multi-step agent reasoning\n",
    "- ✅ Test edge cases and error handling\n",
    "- ✅ Distinguish between agent testing and LLM testing\n",
    "\n",
    "### 📚 Testing Levels Completed\n",
    "\n",
    "**✅ Lesson 1:** Simple LLM Testing\n",
    "- Text outputs\n",
    "- Factual correctness\n",
    "- Structured output validation\n",
    "\n",
    "**✅ Lesson 2:** Agent Testing (This Lesson)\n",
    "- Tool selection\n",
    "- Parameter extraction\n",
    "- Multi-step reasoning\n",
    "- Edge cases\n",
    "\n",
    "**🔜 Lesson 3:** Advanced Testing (Coming Next)\n",
    "- LLM-as-judge for subjective quality\n",
    "- Testing response helpfulness\n",
    "- Testing conversation flow\n",
    "- Integration testing\n",
    "\n",
    "### 💡 Real-World Application\n",
    "\n",
    "You've learned skills applicable to:\n",
    "- 🎫 Customer support agents\n",
    "- 📊 Data analysis agents\n",
    "- 🔧 DevOps automation agents\n",
    "- 📝 Content generation agents\n",
    "- 🔍 Research and retrieval agents\n",
    "\n",
    "---\n",
    "\n",
    "**Excellent work! You've completed Lesson 2: Testing ADK Agents** 🎓\n",
    "\n",
    "You can now test both simple LLMs and complex agents with tools. Next, we'll learn advanced techniques for testing subjective quality using LLM-as-judge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
